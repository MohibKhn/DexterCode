{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non-letter characters and make everything lowercase.\n",
    "train['comment_text'] = train['comment_text'].str.replace('[^a-zA-Z]',' ').str.lower()\n",
    "test['comment_text'] = test['comment_text'].str.replace('[^a-zA-Z]',' ').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits made under my userna...\n",
       "1    d aww  he matches this background colour i m s...\n",
       "2    hey man  i m really not trying to edit war  it...\n",
       "3      more i can t make any real suggestions on im...\n",
       "4    you  sir  are my hero  any chance you remember...\n",
       "5       congratulations from me as well  use the to...\n",
       "6         cocksucker before you piss around on my work\n",
       "7    your vandalism to the matt shirvington article...\n",
       "8    sorry if the word  nonsense  was offensive to ...\n",
       "9    alignment on this subject and which are contra...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = train['comment_text'].str.split()\n",
    "test_split = test['comment_text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lol = train_split.values.tolist()\n",
    "test_lol = test_split.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gensim has support for multi-core systems\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.word2vec.Word2Vec(sentences=train_lol,workers=4,size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "vocab = defaultdict(int)\n",
    "for k, v in w2v.wv.vocab.items():\n",
    "    vocab[k]=v.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Vocab at 0x20f82791358>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([v for k, v in w2v.wv.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41526"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([v for k,v in vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = [[vocab[w] for w in train_split[i]] for i in range(len(train_split))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[660, 76, 0, 129, 132, 178, 30, 648, 4288, 10991, 996, 86, 328, 48, 2148, 21, 11154, 53, 6526, 14, 61, 2634, 150, 2, 2813, 35, 120, 1155, 14992, 2674, 4, 46, 59, 21, 241, 0, 357, 32, 0, 37, 29, 146, 2, 68, 3228, 89], [144, 16357, 50, 2511, 12, 543, 3615, 2, 68, 4322, 2597, 22, 95, 37, 943, 182], [401, 411, 2, 68, 136, 13, 247, 1, 75, 308, 9, 17, 53, 8, 12, 582, 7, 2194, 485, 496, 104, 4, 591, 1, 38, 324, 129, 356, 3, 30, 37, 29, 50, 210, 1, 424, 60, 39, 0, 2281, 94, 0, 709, 461], [60, 2, 36, 21, 98, 56, 325, 1386, 14, 2016, 2, 5725, 23, 0, 124, 2380, 58, 15, 504, 14, 26, 6, 4034, 3, 1262, 3, 9214, 2, 69, 0, 273, 85, 125, 12844, 40, 8, 48, 19, 43, 10, 0, 1409, 140, 1203, 2008, 413, 1203, 316, 2, 36, 34, 8, 504, 14, 23, 47, 51, 288, 105, 116, 23, 5, 18, 56, 4161, 11, 2281, 271, 14, 273, 26, 107, 1, 34, 9, 208, 46, 204, 38, 71, 42, 533, 1, 15, 6, 5635, 14, 80, 11, 376, 40, 2, 617, 42, 85, 15, 6, 1937, 379, 6, 2809, 3098, 77, 9, 17, 414, 10, 0, 496, 614, 3413, 28, 99, 24, 3384, 4623], [5, 1606, 19, 30, 3272, 56, 1027, 5, 564, 41, 29, 8, 17, 14], [2557, 32, 38, 16, 101, 81, 0, 2137, 101, 37], [1797, 149, 5, 3294, 320, 14, 30, 143], [20, 199, 1, 0, 3260, 0, 24, 44, 57, 328, 46, 59, 21, 34, 9, 128, 26, 5, 45, 15, 632], [261, 23, 0, 283, 748, 25, 1417, 1, 5, 482, 2, 68, 13, 8887, 1, 329, 217, 10, 0, 24, 1415, 48, 49, 2762, 14, 38, 11, 199, 2, 68, 1009, 1020, 8, 9, 15, 60, 1332, 40, 51, 36, 81, 9, 11, 460, 16, 6, 270, 2, 18, 57, 1, 0, 4571, 7760, 29, 27, 9, 17, 644, 6, 1308, 9, 656, 1, 2572, 7760, 55, 7, 6, 675, 7480, 24, 8, 1054, 5, 47, 461, 42, 251, 15, 155, 320, 22, 3407, 10, 13632], [10653, 14, 12, 220, 4, 55, 19, 1736, 1, 145, 3, 0]]\n"
     ]
    }
   ],
   "source": [
    "print (train_ind[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = [[vocab[w] for w in test_split[i]] for i in range(len(test_split))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_ind,maxlen=200,truncating='pre')\n",
    "test_padded = pad_sequences(test_ind,maxlen=200,truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n",
      "153164\n"
     ]
    }
   ],
   "source": [
    "print (len(train_padded))\n",
    "print (len(test_padded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 200)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    68,  3228,    89],\n",
       "       [    0,     0,     0, ...,    37,   943,   182],\n",
       "       [    0,     0,     0, ...,     0,   709,   461],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  3297, 12587,  4190],\n",
       "       [    0,     0,     0, ...,   153,    35,     9],\n",
       "       [    0,     0,     0, ...,  1561,  1964,    88]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, GlobalMaxPool1D, BatchNormalization,Embedding\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Embedding, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "embed_size = 50 # how big is each word vector\n",
    "max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 200 # max number of words in a comment to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = w2v.wv.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x20f8085e828>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 100, 300)          12458100  \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 100, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 50, 32)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 50, 100)           33200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 12,525,888\n",
      "Trainable params: 67,588\n",
      "Non-trainable params: 12,458,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "x = emb_layer(inp)\n",
    "\n",
    "x = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "x = Bidirectional(LSTM(50, return_sequences=True,dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "print(model.summary())\n",
    "import keras.backend as K\n",
    "def loss(y_true, y_pred):\n",
    "     return K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/3\n",
      "143613/143613 [==============================] - 462s 3ms/step - loss: 0.2976 - acc: 0.9331 - val_loss: 0.2884 - val_acc: 0.9873 - ETA: 1s - loss: 0.2978 - ac\n",
      "Epoch 2/3\n",
      "143613/143613 [==============================] - 423s 3ms/step - loss: 0.2834 - acc: 0.9818 - val_loss: 0.2843 - val_acc: 0.9842\n",
      "Epoch 3/3\n",
      "143613/143613 [==============================] - 435s 3ms/step - loss: 0.2808 - acc: 0.9816 - val_loss: 0.2852 - val_acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20519d3a1d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "def schedule(ind):\n",
    "    a = [0.002,0.003, 0.000]\n",
    "    return a[ind]\n",
    "lr = callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "model.fit(x=train_padded,y=y,validation_split=.1,epochs=3,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[144, 16196, 50, 2511, 12, 543, 3617, 2, 68, 4321, 2599, 22, 95, 37, 944, 182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_8 to have shape (100,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-d3075f56cc5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#y_classes = keras.np_utils.probas_to_classes(test_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#This is equivalent to model.predict_classes(x) on the Sequential model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected input_8 to have shape (100,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(x=a)\n",
    "y_classes = test_pred.argmax(axis=-1)\n",
    "#y_classes = keras.np_utils.probas_to_classes(test_pred)\n",
    "#This is equivalent to model.predict_classes(x) on the Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5}\n",
      "153164\n",
      "(153164,)\n"
     ]
    }
   ],
   "source": [
    "s=set(y_classes)\n",
    "print(s)\n",
    "print(len(y_classes))\n",
    "print(y_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9835712e-01 3.0494604e-01 9.7802311e-01 4.6374734e-02 9.3047005e-01\n",
      "  3.4360987e-01]\n",
      " [1.7355323e-04 1.7877742e-10 1.8291954e-05 1.9762727e-09 5.5348914e-06\n",
      "  3.7253318e-07]\n",
      " [1.1260275e-02 4.8330803e-06 5.3420700e-03 4.6667701e-06 1.5321537e-03\n",
      "  1.1742234e-04]\n",
      " ...\n",
      " [2.6474227e-05 1.7033279e-10 1.3006506e-06 1.5546626e-09 7.0798382e-07\n",
      "  1.7949057e-07]\n",
      " [3.3716680e-04 6.0020696e-08 6.6738885e-06 2.6853630e-07 7.1242816e-06\n",
      "  6.0562029e-06]\n",
      " [8.0460435e-01 7.7419532e-03 5.2338749e-01 8.1460609e-04 2.1585009e-01\n",
      "  2.9234942e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
